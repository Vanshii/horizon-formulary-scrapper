# ğŸŒ Horizon Formulary Scraper & Query System

An **AI-powered drug formulary scraper and query assistant** that extracts, processes, and answers questions from Horizon BCBSNJâ€™s formulary data.  
The system scrapes the drug formulary webpage, parses structured data, stores it locally, and allows intelligent querying through a frontend interface.

---

## ğŸš€ Features

- **Automated Web Scraping:** Extracts and parses formulary data from HTML pages.  
- **AI Query Engine:** Uses Gemini / OpenAI API to answer natural language queries about drugs.  
- **Search Interface:** React + Vite frontend for interactive queries.  
- **Backend Processing:** Python-based scraper and semantic search logic.  
- **Local Storage:** Stores parsed data as JSON and CSV for offline analysis.

---

## ğŸ—ï¸ Project Structure

HORIZON-FORMULARY-SCRAPER/
â”‚                          
â”œâ”€â”€ backend/                    
â”‚   â”œâ”€â”€ run.py                   # Main entry point for backend  
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies  
â”‚   â”œâ”€â”€ .env                     # Environment variables (API keys, etc.)  
â”‚   â”œâ”€â”€ src/                     # Parsing and scraping logic  
â”‚   â”œâ”€â”€ data/                    # Local data cache  
â”‚   â”‚   â”œâ”€â”€ preferred_drugs.json  
â”‚   â”‚   â””â”€â”€ preferred_drugs.csv  
â”‚   â””â”€â”€ page2.html               # Example HTML file used for local scraping  
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/                     # React + Vite frontend code  
â”‚   â”œâ”€â”€ index.html  
â”‚   â”œâ”€â”€ package.json  
â”‚   â””â”€â”€ vite.config.js  
â”‚
â””â”€â”€ README.md

---

## âš™ï¸ Setup Instructions

### ğŸ§© 1. Clone the Repository

- `git clone https://github.com/yourusername/horizon-formulary-scraper.git`
- `cd horizon-formulary-scraper`




**ğŸ 2. Backend Setup**

- **Go to backend folder**
  - `cd backend`

- **Install dependencies:**
  - `pip install -r requirements.txt`

- **Set up environment variables (temporary):**
  - For Gemini API:
    - `export GEMINI_API_KEY="your_api_key_here"`        # macOS/Linux
    - `set GEMINI_API_KEY=your_api_key_here`             # Windows CMD
  - Alternatively, create a `.env` file in the backend folder:
    - `GEMINI_API_KEY=your_api_key_here`

---

**âš›ï¸ 4. Frontend Setup (React + Vite)**

- **Go to backend folder**
  - `cd frontend`
- **Install dependencies:**
  - `npm install`
- **Start the server:**
  - `npm run dev`

Then open the displayed local URL (usually `http://localhost:5173/`) in your browser.


**ğŸ§° Example Commands**

- **Run backend:**
  - `python run.py`

- **Run frontend:**
  - `npm run dev`

- **Check API key:**
  - macOS/Linux: `echo $GEMINI_API_KEY`
  - Windows PowerShell: `echo $env:GEMINI_API_KEY`

---

**ğŸ§­ Environment Variables**

| Variable        | Description                  | Example           |
|-----------------|-----------------------------|-----------------|
| GEMINI_API_KEY  | API key for Google Gemini    | AIzaSyDxxxxxxx  |
| OPENAI_API_KEY  | (Optional) OpenAI API key   | sk-xxxxxx       |

---

**ğŸ§± Example Response Flow**

| Step | Component | Action |
|------|----------|--------|
| 1    | Frontend | User enters drug query |
| 2    | Backend  | Fetches embeddings and formulary data |
| 3    | AI Engine | Generates response using Gemini/OpenAI |
| 4    | Frontend | Displays answer neatly |

---

**ğŸš§ Extending to Production**

To move this system into a production-grade service, you can:

- âœ… Use FastAPI or Flask for a persistent backend API  
- âœ… Host the model on Google Cloud Run or AWS Lambda  
- âœ… Store data in a vector database (e.g., Pinecone, Chroma, FAISS server)  
- âœ… Add authentication & rate limiting for secure API access  
- âœ… Deploy frontend via Vercel or Netlify  
- âœ… Integrate real-time scraping or scheduled updates via Celery + Redis

---

**ğŸ§‘â€ğŸ’» Author**

Vanshika Dahiya  
AI Engineer â€” Horizon Formulary Scraper Project

---

**ğŸªª License**

This project is for educational and research purposes only.  
All scraped content belongs to their respective sources.
